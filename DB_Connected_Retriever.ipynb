{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "O_N87YLjB9tG",
        "0N2PlSJCCIbA",
        "VBy8ZA3zCQEn",
        "B-IVT2fkDEkL"
      ],
      "authorship_tag": "ABX9TyNfKwVrHlhLm9+lZ7y5seSB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkaramb/CloudWeaver/blob/retriever-chain-connection/DB_Connected_Retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "O_N87YLjB9tG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8eFjLBxNLGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a71e9378-51cd-48f0-e107-0f0f6ebc896a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m583.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.8/146.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.5/664.5 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -U --upgrade --quiet langchain-google-vertexai langchain-google-genai langchain-core langchain-community langchain unstructured lark chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyA7lgFVJCMuPk6V5xm-jxMHh8ndOpo69pY'"
      ],
      "metadata": {
        "id": "q01k3cGoNWyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdztslzkNajN",
        "outputId": "2f2ce0c3-c0ae-4b73-c584-c02cbc0c5118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)"
      ],
      "metadata": {
        "id": "cxQ2nKVtCdmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Access Database contents and metadata"
      ],
      "metadata": {
        "id": "0N2PlSJCCIbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/cw_db_metadata.pkl'"
      ],
      "metadata": {
        "id": "La7hi5UeNbML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the file\n",
        "with open(file_path, 'rb') as file:\n",
        "    documents = pickle.load(file)"
      ],
      "metadata": {
        "id": "qoV2NUzlNwrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents[1356].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDBon6kNR-S8",
        "outputId": "cdfb00e2-4f86-4f8c-9ece-55ffd47a6ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "/******************************************\n",
            "\tRoutes\n",
            " *****************************************/\n",
            "resource \"google_compute_route\" \"route\" {\n",
            "  provider = google-beta\n",
            "  count    = var.routes_count\n",
            "\n",
            "  project = var.project_id\n",
            "  network = var.network_name\n",
            "\n",
            "  name                   = lookup(var.routes[count.index], \"name\", format(\"%s-%s-%d\", lower(var.network_name), \"route\", count.index))\n",
            "  description            = lookup(var.routes[count.index], \"description\", null)\n",
            "  tags                   = compact(split(\",\", lookup(var.routes[count.index], \"tags\", \"\")))\n",
            "  dest_range             = lookup(var.routes[count.index], \"destination_range\", null)\n",
            "  next_hop_gateway       = lookup(var.routes[count.index], \"next_hop_internet\", \"false\") == \"true\" ? \"default-internet-gateway\" : null\n",
            "  next_hop_ip            = lookup(var.routes[count.index], \"next_hop_ip\", null)\n",
            "  next_hop_instance      = lookup(var.routes[count.index], \"next_hop_instance\", null)\n",
            "  next_hop_instance_zone = lookup(var.routes[count.index], \"next_hop_instance_zone\", null)\n",
            "  next_hop_vpn_tunnel    = lookup(var.routes[count.index], \"next_hop_vpn_tunnel\", null)\n",
            "  next_hop_ilb           = lookup(var.routes[count.index], \"next_hop_ilb\", null)\n",
            "  priority               = lookup(var.routes[count.index], \"priority\", null)\n",
            "\n",
            "  depends_on = [var.module_depends_on]\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retriever"
      ],
      "metadata": {
        "id": "VBy8ZA3zCQEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
        "\n",
        "doc_embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\", task_type=\"retrieval_document\"\n",
        ")\n",
        "\n",
        "# Assuming you've already filtered 'documents' to exclude those with empty 'page_content'\n",
        "# as shown in the previous code snippet:\n",
        "filtered_documents = [doc for doc in documents if doc.page_content and doc.page_content.strip()]\n",
        "\n",
        "# Assuming 'filtered_documents' is your list of Document objects ready for processing\n",
        "# Apply the filter to clean up metadata in your documents\n",
        "cleaned_documents = filter_complex_metadata(filtered_documents)\n",
        "\n",
        "# Now that the documents have been cleaned, you can proceed with creating the vector store\n",
        "vectorstore = Chroma.from_documents(documents=cleaned_documents, embedding=doc_embeddings, persist_directory=\"./chroma_db\")\n"
      ],
      "metadata": {
        "id": "rh5kZCMrCWk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Chroma from disk\n",
        "vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=doc_embeddings)\n",
        "docs = db2.similarity_search(\"query\")\n",
        "print(docs[0].page_content)  # This should output the same result if the data was saved and loaded correctly\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIJWjIZ4Aqtj",
        "outputId": "3cfcc6d0-7232-49b8-a3cb-65c0f70cf9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "variable \"project_id\" {\n",
            "  type = string\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r /content/chroma_db.zip /content/chroma_db\n",
        "\n",
        "files.download('chroma_db.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "dnhjTibDDFGy",
        "outputId": "4fac029f-2d3e-4fe4-943d-2479ed4d9926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/chroma_db/ (stored 0%)\n",
            "  adding: content/chroma_db/f83c1f12-eb2a-446b-a3b7-3673b0290933/ (stored 0%)\n",
            "  adding: content/chroma_db/f83c1f12-eb2a-446b-a3b7-3673b0290933/header.bin (deflated 57%)\n",
            "  adding: content/chroma_db/f83c1f12-eb2a-446b-a3b7-3673b0290933/data_level0.bin (deflated 11%)\n",
            "  adding: content/chroma_db/f83c1f12-eb2a-446b-a3b7-3673b0290933/index_metadata.pickle (deflated 38%)\n",
            "  adding: content/chroma_db/f83c1f12-eb2a-446b-a3b7-3673b0290933/length.bin (deflated 58%)\n",
            "  adding: content/chroma_db/f83c1f12-eb2a-446b-a3b7-3673b0290933/link_lists.bin (deflated 87%)\n",
            "  adding: content/chroma_db/chroma.sqlite3 (deflated 56%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d1d96b8a-6069-417a-b91f-dbd2b0ee06a2\", \"chroma_db.zip\", 18292971)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "\n",
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"sub_instance\",\n",
        "        description=\"Specifies the exact variant or configuration of the instance that the Terraform code represents. This allows for precise identification of Terraform files based on specific implementations, such as a MySQL version for a Cloud SQL instance, enabling targeted retrieval of code.\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"product\",\n",
        "        description=\"Identifies the broader GCP product category to which an instance belongs. For example, a Compute Engine VM or a Cloud SQL database would fall under 'compute' and 'sql' resources, respectively. This categorization facilitates the organization and search of Terraform files within the context of GCP products.\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"instance\",\n",
        "        description=\"Denotes the specific instance within a GCP product that the Terraform code is designed to provision or manage. This could refer to a particular VM, database, or storage bucket, among others. The instance name aids in pinpointing Terraform files that apply to particular GCP service instances.\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"folder_type\",\n",
        "        description=\"\"\"Modules folder_type:\n",
        "This directory contains Terraform modules, which are pre-packaged configurations for specific use cases. Each module comprises resource and module blocks that encapsulate standard configurations for GCP products or functionalities. These modules are designed for reuse across different parts of the project or in other projects, promoting efficient and scalable infrastructure setups.\n",
        "\n",
        "Examples folder_type:\n",
        "The examples directory showcases how to use the Terraform modules from the modules directory in practical deployments. It includes sample Terraform configurations that reference and instantiate the modules, providing clear, real-world scenarios of module application. This directory is instrumental in demonstrating the modules' utility and easing their adoption by offering ready-to-use examples. \"\"\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"type\",\n",
        "        description=\"\"\"In a Terraform project aimed at deploying and managing resources on the Google Cloud Platform (GCP), three critical files play unique roles in ensuring the configuration's flexibility, clarity, and operational efficiency. These files—`variables.tf`, `main.tf`, and `outputs.tf`—each serve distinct purposes within the Terraform infrastructure as code (IaC) framework.\n",
        "\n",
        "Variables.tf:\n",
        "\n",
        "The `variables.tf` file is fundamental for defining and organizing variables to customize infrastructure deployments across various environments. Each variable is declared with a name, type, description, and optionally, a default value. This structure not only aids in making Terraform configurations modular and reusable but also enhances the maintainability of the code. Variables range from simple placeholders (e.g., project IDs, geographical locations) to complex structures for detailed resource definitions, embodying the principles of IaC by promoting a systematic and customizable approach to cloud resource deployment.\n",
        "\n",
        "Main.tf:\n",
        "\n",
        "At the core of a Terraform project, the `main.tf` file orchestrates the deployment of GCP resources. It integrates:\n",
        "\n",
        "- **Local Variables (`locals`)** to centralize configurations, reducing repetition and enhancing configuration clarity.\n",
        "- **Resource Blocks** to define the GCP resources to be managed or provisioned, including IAM roles and storage buckets.\n",
        "- **Modules** to encapsulate and reuse configurations for efficient resource management.\n",
        "- **Data Sources (`data`)** to incorporate data from GCP or external sources for informed configuration steps.\n",
        "- **IAM and Permissions** to detail the setup for service accounts and specify roles for secure access management.\n",
        "\n",
        "This file exemplifies the declarative nature of IaC, showcasing Terraform's capability to manage a diverse array of resources on GCP through a structured and scalable configuration.\n",
        "\n",
        "Outputs.tf:\n",
        "\n",
        "The `outputs.tf` file is dedicated to defining output variables that relay crucial deployment information to the user. These outputs highlight essential details such as resource identifiers, names, descriptions, and project-specific information, bridging the gap between complex configurations and actionable insights. By making critical deployment information accessible, the outputs.tf file not only enhances the transparency of cloud resources but also supports further automation, integration, and management tasks, emphasizing the importance of information accessibility in IaC practices.\n",
        "\n",
        "README.md:\n",
        "\n",
        "The README.md file serves as the project's documentation hub, containing critical information on how to use the Terraform product, module, or example. It outlines expected inputs, outputs, dependencies, requirements, and use cases, offering a comprehensive guide to navigating and utilizing the Terraform configuration effectively. This file ensures that users have a clear understanding of the project's scope, functionalities, and operational requirements, making it an indispensable resource for successful deployment.\n",
        "Together, these files provide a solid framework for managing infrastructure on GCP with Terraform, leveraging the full potential of IaC to deliver adaptable, scalable, and efficiently managed cloud resources, complemented by thorough documentation for user guidance and project clarity.\n",
        "\n",
        "Together, these files constitute a robust framework for managing infrastructure on GCP with Terraform, leveraging the strengths of IaC to deliver adaptable, scalable, and efficient cloud resource management. \"\"\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "]\n"
      ],
      "metadata": {
        "id": "2hlwJugdRXyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "\n",
        "document_content_description = \"Examples of different components of GCP terraform instances and modules along with readmes describing them.\"\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    model,\n",
        "    vectorstore,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        "    enable_limit=True,\n",
        ")"
      ],
      "metadata": {
        "id": "tO9EZBcYCtQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain"
      ],
      "metadata": {
        "id": "B-IVT2fkDEkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/terraform-linters/tflint/releases/download/v0.34.1/tflint_linux_amd64.zip\n",
        "!unzip tflint_linux_amd64.zip\n",
        "!chmod +x tflint\n",
        "\n",
        "!mv tflint /usr/local/bin/\n",
        "!tflint --version"
      ],
      "metadata": {
        "id": "g97Ka-EJkieY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01003f2c-47f6-43ee-b224-493949275a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-22 20:38:41--  https://github.com/terraform-linters/tflint/releases/download/v0.34.1/tflint_linux_amd64.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/71487396/53f1e0b7-c511-4d4a-9502-5f73e081eebf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240422T203841Z&X-Amz-Expires=300&X-Amz-Signature=8aa8b67d4b07ef11a58ff776aa95714437d9409da4adab8c612a3aa292ccafaa&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=71487396&response-content-disposition=attachment%3B%20filename%3Dtflint_linux_amd64.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-22 20:38:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/71487396/53f1e0b7-c511-4d4a-9502-5f73e081eebf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240422T203841Z&X-Amz-Expires=300&X-Amz-Signature=8aa8b67d4b07ef11a58ff776aa95714437d9409da4adab8c612a3aa292ccafaa&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=71487396&response-content-disposition=attachment%3B%20filename%3Dtflint_linux_amd64.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11179589 (11M) [application/octet-stream]\n",
            "Saving to: ‘tflint_linux_amd64.zip.1’\n",
            "\n",
            "\rtflint_linux_amd64.   0%[                    ]       0  --.-KB/s               \rtflint_linux_amd64. 100%[===================>]  10.66M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-04-22 20:38:41 (192 MB/s) - ‘tflint_linux_amd64.zip.1’ saved [11179589/11179589]\n",
            "\n",
            "Archive:  tflint_linux_amd64.zip\n",
            "  inflating: tflint                  \n",
            "TFLint version 0.34.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import tempfile\n",
        "\n",
        "def lint_terraform_code(code):\n",
        "\n",
        "  clean_code = code.replace(\"```\", \"\")\n",
        "\n",
        "  with tempfile.NamedTemporaryFile(delete=False, suffix=\".tf\") as temp_file:\n",
        "    temp_file_name = temp_file.name\n",
        "    temp_file.write(clean_code.encode('utf-8'))\n",
        "\n",
        "  # Write the code to a temporary file\n",
        "  #with open(\"generated.tf\", \"w\") as file:\n",
        "        #file.write(clean_code)\n",
        "\n",
        "  # Run the linter on the file\n",
        "  result = subprocess.run([\"tflint\", temp_file_name], capture_output=True, text=True)\n",
        "\n",
        "  # Ensure the temporary file is removed after linting\n",
        "  os.unlink(temp_file_name)\n",
        "\n",
        "\n",
        "  # Return linting results\n",
        "  return result.stdout + \"\\n\" + result.stderr"
      ],
      "metadata": {
        "id": "l-eEx4MukeTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "# Define the initial prompt template for generating project architecture\n",
        "architecture_prompt_template = \"\"\"Given the detailed project description and user feedback below, generate an optimized initial architecture outline suitable for deployment on Google Cloud Platform (GCP) using Terraform. Aim for a design that balances performance, cost, security, and scalability. Include considerations for key GCP services, data storage options, compute resources, networking setup, and any specific security policies or compliance requirements mentioned. Suggest potential areas for cost optimization without compromising on performance. Address any concerns or modifications suggested in the user feedback explicitly, proposing how the architecture can be adjusted to meet these insights.\n",
        "\n",
        "Project Description:\n",
        "{project_description}\n",
        "\n",
        "User Architecture Feedback:\n",
        "{user_architecture_feedback}\n",
        "\n",
        "To ensure a comprehensive understanding, please include the following in the Initial Architecture Outline:\n",
        "1. A high-level diagram (descriptive) of the proposed architecture, indicating the interaction between different GCP services.\n",
        "2. A list of recommended GCP services and tools, with brief explanations for their selection.\n",
        "3. An overview of the data flow and storage strategy, considering data volume, velocity, and variety.\n",
        "4. Proposed networking and security configurations, including any VPCs, subnets, firewalls, and identity and access management (IAM) roles.\n",
        "5. Strategies for monitoring, logging, and alerting to ensure system health and performance.\n",
        "6. Any initial Terraform configurations or module recommendations that can jump-start the deployment process.\n",
        "7. Suggestions for handling scalability, including any auto-scaling or load balancing configurations.\n",
        "8. Considerations for disaster recovery and data backup strategies to ensure business continuity.\n",
        "\n",
        "Feel free to request additional information or clarification if the project description or user feedback lacks specific details necessary for a well-rounded proposal.\"\"\"\n",
        "\n",
        "\n",
        "# Define the prompt template for generating Terraform code based on confirmed architecture\n",
        "terraform_prompt_template = \"\"\"\n",
        "Given the confirmed architecture outline detailed below, your task is to generate comprehensive Terraform code suitable for deploying the specified project on Google Cloud Platform (GCP). The generated code should accurately reflect the unique infrastructure requirements outlined, emphasizing scalability, security, and cost-efficiency. Utilize the retriever's library of Terraform files — categorized by product and resource, with accompanying README files — as a foundation for your code. This library will serve as a valuable resource for identifying pre-existing configurations that align with the project's needs, thereby streamlining the code development process.\n",
        "\n",
        "When constructing your Terraform configurations, ensure they are tailored to the project's specific requirements by:\n",
        "1. Selecting appropriate GCP services and configuring them to form a secure, scalable, and cost-effective infrastructure.\n",
        "2. Incorporating a Google Compute Engine instance with specifications that support the application's performance needs while optimizing costs.\n",
        "3. Establishing a comprehensive networking setup including VPCs, subnets, and firewall rules to ensure a secure operational environment.\n",
        "4. Defining necessary IAM roles and policies for secure access management across GCP services.\n",
        "5. Integrating storage solutions that accommodate the application's data handling requirements.\n",
        "6. Planning for future growth with scalable solutions like Load Balancing and autoscaling.\n",
        "7. Embedding monitoring, logging, and alerting mechanisms to facilitate efficient infrastructure management.\n",
        "8. Structuring the code for modularity, reusability, and clarity, incorporating documentation where beneficial.\n",
        "\n",
        "Additionally, address any user feedback provided to refine and adjust the Terraform code, focusing on improvements in security, scalability, and efficiency. Your final output should not only align with the confirmed architecture outline but also adhere to best practices in cloud infrastructure design.\n",
        "\n",
        "Confirmed Architecture Outline:\n",
        "{confirmed_architecture}\n",
        "\n",
        "Existing Terraform Code (if any):\n",
        "{existing_terraform_code}\n",
        "\n",
        "User Feedback:\n",
        "{user_terraform_feedback}\n",
        "\n",
        "Your Terraform Code:\n",
        "\"\"\"\n",
        "\n",
        "# Define the prompt template the incorporate the tflint results in the final code generated\n",
        "corrected_terraform_template = \"\"\"\n",
        "\n",
        "Task Description:\n",
        "You will be given the output of `tflint`, a Terraform linter, and a corresponding Terraform script. Your task is to interpret this output, identify issues flagged by the linter, and apply corrections to the Terraform script accordingly. Follow these steps to ensure accuracy and compliance with Terraform standards.\n",
        "\n",
        "Steps to Follow:\n",
        "\n",
        "1. Review `tflint` Output:\n",
        "   - Start by examining the `tflint` output provided. It will detail specific issues including the type of issue, its severity, and the exact location within the Terraform script (file and line number).\n",
        "\n",
        "2. Analyze Each Issue:\n",
        "   - For every issue listed by `tflint`, evaluate the context and the code surrounding the flagged location to understand why it was marked. This includes syntax errors, deprecated elements, and best practice deviations.\n",
        "\n",
        "3. Apply Corrections:\n",
        "   - Direct Corrections: Adjust the script to resolve straightforward issues such as syntax errors or incorrect attribute names according to Terraform’s documentation.\n",
        "   - Best Practices: Update the script to replace hard-coded values with variables, add missing descriptions, or improve resource configurations as recommended by `tflint`.\n",
        "\n",
        "4. Document Changes:\n",
        "   - Add comments within the script next to each change. Briefly describe why the change was made to help with future maintenance and understanding.\n",
        "\n",
        "5. Validation:\n",
        "   - After implementing the changes, check the overall script to ensure that it still aligns with Terraform's syntax and best practices and that no new issues have been introduced.\n",
        "\n",
        "6. Output the Revised Script:\n",
        "   - Provide the corrected Terraform script, highlighting the changes made. Also, include a summary of each correction addressing the specific issues identified by `tflint`.\n",
        "\n",
        "Objective:\n",
        "The goal is to enhance the quality and compliance of the Terraform script based on the `tflint` feedback, making precise corrections without altering the script’s fundamental functionality or intent.\n",
        "\n",
        "Please provide the output in a JSON format with two keys: 'corrected_terraform_code' and 'linting_summary'. The 'corrected_terraform_code' key should contain the formatted Terraform code enclosed in triple backticks for better readability. The 'linting_summary' should provide a markdown-formatted summary of the changes made, including headers and bullet points to outline corrections and important notes. Each key's content should be clear and easy to follow, making it straightforward for developers to understand the corrections and their implications on the code.\n",
        "\n",
        "Existing Terraform Code:\n",
        "{existing_terraform_code}\n",
        "\n",
        "Linter Feedback (`tflint` Output):\n",
        "{tflint_terraform_feedback}\n",
        "\n",
        "Corrected Terraform Code:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Custom prompt templates\n",
        "architecture_prompt = PromptTemplate.from_template(\n",
        "    architecture_prompt_template)\n",
        "terraform_code_prompt = PromptTemplate.from_template(\n",
        "    terraform_prompt_template)\n",
        "\n",
        "# Define the interaction chain for architecture generation and confirmation\n",
        "architecture_chain = ({\n",
        "    \"project_description\": RunnablePassthrough(),\n",
        "    \"user_architecture_feedback\": RunnablePassthrough()\n",
        "}\n",
        "    | architecture_prompt\n",
        "    | model\n",
        "    | StrOutputParser())\n",
        "\n",
        "# Define the interaction chain for Terraform code generation\n",
        "terraform_code_chain = ({\n",
        "    \"context\": retriever,\n",
        "    \"confirmed_architecture\": RunnablePassthrough(),\n",
        "    \"existing_terraform_code\": RunnablePassthrough(),\n",
        "    \"user_terraform_feedback\": RunnablePassthrough(),\n",
        "}\n",
        "    | terraform_code_prompt\n",
        "    | model\n",
        "    | StrOutputParser())\n",
        "\n",
        "# Define the prompt template for suggesting improvements\n",
        "improvement_prompt_template = \"\"\"\n",
        "Given the confirmed architecture outline below, suggest potential improvements that could enhance the project's efficiency, scalability, or reliability.\n",
        "\n",
        "Confirmed Architecture Outline:\n",
        "{confirmed_architecture}\n",
        "\n",
        "Suggested Improvements:\"\"\"\n",
        "\n",
        "improvement_prompt = PromptTemplate.from_template(\n",
        "    improvement_prompt_template)\n",
        "\n",
        "# Define the interaction chain for improvement suggestions\n",
        "improvement_chain = ({\n",
        "    \"context\": retriever,\n",
        "    \"confirmed_architecture\": RunnablePassthrough()\n",
        "}\n",
        "    | improvement_prompt\n",
        "    | model\n",
        "    | StrOutputParser())\n",
        "\n",
        "lint_prompt = PromptTemplate.from_template(\n",
        "    corrected_terraform_template,\n",
        "    additional_instructions=\"Review the linter feedback closely and modify the Terraform script to address each specific issue reported. Ensure to add comments explaining each change for future reference.\"\n",
        "    )\n",
        "\n",
        "# Define the interaction chain for the LLM to communicate with the linter results\n",
        "finalized_code_chain = ({\n",
        "    \"context\": retriever,\n",
        "    \"existing_terraform_code\": RunnablePassthrough(),\n",
        "    \"tflint_terraform_feedback\": RunnablePassthrough()\n",
        "}\n",
        "    | lint_prompt\n",
        "    | model\n",
        "    | StrOutputParser())\n",
        "\n",
        "project_description = input(\"Enter the project description: \")\n",
        "\n",
        "user_architecture_feedback = \"Initial Feedback (None)\"\n",
        "user_terraform_feedback = \"Initial Feedback (None)\"\n",
        "existing_terraform_code = \"\"\n",
        "\n",
        "architecture = None\n",
        "while not architecture:\n",
        "  try:\n",
        "    architecture = architecture_chain.invoke({\n",
        "        \"project_description\": project_description,\n",
        "        \"user_architecture_feedback\": \"user_architecture_feedback\"\n",
        "    })\n",
        "  except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "    break\n",
        "\n",
        "  print(\"Generated Architecture: \", architecture)\n",
        "  user_confirmation = input(\"User confirms this architecture? (yes/no): \")\n",
        "  if user_confirmation.lower() == 'yes':\n",
        "    break\n",
        "  else:\n",
        "    user_architecture_feedback = input(\"Please describe the issues you have with the architecture: \")\n",
        "\n",
        "improvements = improvement_chain.invoke(\n",
        "  {\"confirmed_architecture\": architecture})\n",
        "\n",
        "# Display the suggested improvements to the user\n",
        "print(\"Suggested Improvements: \", improvements)\n",
        "user_confirmation = input(\n",
        "  \"Would you like to incorporate suggested improvements? (yes/no): \")\n",
        "\n",
        "if user_confirmation.lower() == 'yes':\n",
        "    # Update the architecture with the improvements\n",
        "    architecture += \"\\n\\nIncorporated Improvements:\\n\" + improvements\n",
        "\n",
        "# print()\n",
        "# print(architecture)\n",
        "terraform_code_correct = False\n",
        "terraform_code_generated = None\n",
        "while terraform_code_correct == False:\n",
        "  print(\"Architecture: \", architecture)\n",
        "  try:\n",
        "    terraform_code_generated = terraform_code_chain.invoke({\n",
        "        \"confirmed_architecture\": architecture,\n",
        "        \"existing_terraform_code\": existing_terraform_code,\n",
        "        \"user_terraform_feedback\": user_terraform_feedback\n",
        "    })\n",
        "\n",
        "    linter_feedback = lint_terraform_code(terraform_code_generated)\n",
        "\n",
        "    finalized_code = finalized_code_chain.invoke({\n",
        "        \"existing_terraform_code\": terraform_code_generated,\n",
        "        \"tflint_terraform_feedback\": linter_feedback\n",
        "    })\n",
        "\n",
        "    formatted_code = finalized_code.replace(\"\\\\n\", \"\\n\")\n",
        "    print(\"Generated Terraform Code: \", formatted_code)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "    break\n",
        "\n",
        "  #print(\"Generated Terraform Code: \", terraform_code_generated)\n",
        "  #print(\"Generated Terraform Code: \", finalized_code)\n",
        "  user_confirmed_terraform_code = input(\"User confirms this Terraform code? (yes/no): \")\n",
        "  if user_confirmed_terraform_code.lower() == 'yes':\n",
        "    terraform_code_correct = True\n",
        "  else:\n",
        "      existing_terraform_code = terraform_code_generated\n",
        "      user_terraform_feedback = input(\"What is wrong with the code? \")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DgOh58tLDDan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ecdf9d-5ed8-497e-b2f6-56451b4d9f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the project description: Generate a Google Cloud deployment that can safely handle a few thousand users visiting my online store page.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:308: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Architecture:  ## Optimized Initial Architecture Outline for GCP Deployment\n",
            "\n",
            "### High-Level Architecture Diagram\n",
            "\n",
            "[Image of a high-level architecture diagram, indicating the interaction between different GCP services. The diagram should include the following components:\n",
            "- Cloud Load Balancer\n",
            "- Web Server (GCE/GKE)\n",
            "- Cloud SQL\n",
            "- Cloud Storage\n",
            "- Cloud Pub/Sub\n",
            "- Cloud Functions\n",
            "- Stackdriver Logging/Monitoring]\n",
            "\n",
            "### Recommended GCP Services and Tools\n",
            "\n",
            "- **Cloud Load Balancer:** Distributes incoming traffic across multiple backend servers.\n",
            "- **Web Server (GCE/GKE):** Hosts the online store application.\n",
            "- **Cloud SQL:** Manages the relational database for the store.\n",
            "- **Cloud Storage:** Stores images, videos, and other static content.\n",
            "- **Cloud Pub/Sub:** Facilitates communication between different components.\n",
            "- **Cloud Functions:** Handles asynchronous tasks and event-driven operations.\n",
            "- **Stackdriver Logging/Monitoring:** Provides real-time insights into system performance and health.\n",
            "\n",
            "### Data Flow and Storage Strategy\n",
            "\n",
            "- **Data Volume:** A few thousand users visiting the store page.\n",
            "- **Data Velocity:** Moderate, with occasional bursts of traffic.\n",
            "- **Data Variety:** Structured data (user accounts, order details) and unstructured data (images, videos).\n",
            "- **Storage:**\n",
            "    - **Cloud SQL:** Relational database for structured data.\n",
            "    - **Cloud Storage:** Object storage for unstructured data.\n",
            "\n",
            "### Networking and Security Configurations\n",
            "\n",
            "- **VPC and Subnets:** Create a VPC with multiple subnets for different components.\n",
            "- **Firewalls:** Implement firewall rules to restrict access to specific ports and IP addresses.\n",
            "- **IAM Roles:** Assign appropriate IAM roles to users and service accounts.\n",
            "\n",
            "### Monitoring, Logging, and Alerting\n",
            "\n",
            "- **Stackdriver Logging:** Collect and analyze logs from all components.\n",
            "- **Stackdriver Monitoring:** Monitor system metrics and set up alerts for critical events.\n",
            "\n",
            "### Terraform Configurations and Module Recommendations\n",
            "\n",
            "- **Terraform Modules:**\n",
            "    - **VPC and Subnets:** https://registry.terraform.io/modules/terraform-google-modules/vpc/google\n",
            "    - **Cloud SQL:** https://registry.terraform.io/modules/terraform-google-modules/cloudsql/google\n",
            "    - **Cloud Storage:** https://registry.terraform.io/modules/terraform-google-modules/storage/google\n",
            "- **Initial Terraform Configuration:**\n",
            "```\n",
            "resource \"google_compute_network\" \"default\" {\n",
            "  name = \"my-network\"\n",
            "}\n",
            "\n",
            "resource \"google_compute_subnetwork\" \"default\" {\n",
            "  name          = \"my-subnet\"\n",
            "  network       = google_compute_network.default.id\n",
            "  ip_cidr_range = \"10.0.0.0/24\"\n",
            "}\n",
            "\n",
            "resource \"google_cloud_sql_database\" \"default\" {\n",
            "  name         = \"my-database\"\n",
            "  database     = \"my-database\"\n",
            "  instance_type = \"db-f1-micro\"\n",
            "}\n",
            "\n",
            "resource \"google_storage_bucket\" \"default\" {\n",
            "  name          = \"my-bucket\"\n",
            "  location      = \"US-CENTRAL1\"\n",
            "  force_destroy = true\n",
            "}\n",
            "```\n",
            "\n",
            "### Scalability Considerations\n",
            "\n",
            "- **Auto-Scaling:** Scale GCE/GKE instances based on traffic load.\n",
            "- **Load Balancing:** Distribute traffic across multiple instances using Cloud Load Balancer.\n",
            "\n",
            "### Disaster Recovery and Data Backup\n",
            "\n",
            "- **Data Backup:** Regularly back up data in Cloud SQL and Cloud Storage.\n",
            "- **Disaster Recovery:** Implement a disaster recovery plan to restore the system in case of a failure.\n",
            "\n",
            "### Cost Optimization\n",
            "\n",
            "- **Right-size Instances:** Select the appropriate instance types for GCE/GKE based on expected traffic.\n",
            "- **Spot Instances:** Use Spot Instances for GCE/GKE to save on compute costs.\n",
            "- **Cloud Storage Classes:** Optimize storage costs by using the appropriate storage class for different types of data.\n",
            "User confirms this architecture? (yes/no): yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:308: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:308: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suggested Improvements:  **Efficiency Enhancements:**\n",
            "\n",
            "* **Caching:** Implement caching mechanisms (e.g., Redis, Memcached) to reduce database load and improve response times.\n",
            "* **Asynchronous Processing:** Utilize Cloud Functions or Cloud Tasks to handle non-critical tasks asynchronously, freeing up resources for core operations.\n",
            "* **Optimized Database Indexing:** Ensure that Cloud SQL databases are properly indexed to optimize query performance.\n",
            "\n",
            "**Scalability Enhancements:**\n",
            "\n",
            "* **Horizontal Pod Autoscaling (HPA):** Enable HPA for GKE clusters to automatically scale the number of pods based on CPU or memory utilization.\n",
            "* **Managed Instance Groups (MIG):** Use MIGs for GCE instances to automate instance scaling and load balancing.\n",
            "* **Multi-Region Deployment:** Consider deploying the application across multiple GCP regions to improve fault tolerance and reduce latency for geographically dispersed users.\n",
            "\n",
            "**Reliability Enhancements:**\n",
            "\n",
            "* **High Availability Databases:** Utilize Cloud SQL's high availability feature to create replica instances and ensure data redundancy.\n",
            "* **Redundant Storage:** Implement cross-region replication for Cloud Storage buckets to protect against regional outages.\n",
            "* **Disaster Recovery Plan:** Develop a comprehensive disaster recovery plan that includes automated failover and data restoration procedures.\n",
            "\n",
            "**Cost Optimization Enhancements:**\n",
            "\n",
            "* **Preemptible Instances:** Utilize preemptible GCE or GKE instances for non-critical workloads that can tolerate interruptions.\n",
            "* **Committed Use Discounts:** Explore committed use discounts for Cloud SQL and GCE instances to reduce long-term costs.\n",
            "* **Cloud Billing Alerts:** Set up Cloud Billing alerts to monitor and control project spending.\n",
            "\n",
            "**Other Considerations:**\n",
            "\n",
            "* **Serverless Architecture:** Consider migrating certain components (e.g., Cloud Functions, data processing) to serverless services to reduce infrastructure management overhead.\n",
            "* **Performance Monitoring:** Implement performance monitoring tools (e.g., New Relic, Datadog) to continuously monitor system metrics and identify bottlenecks.\n",
            "* **Security Best Practices:** Regularly review and update security configurations to ensure compliance with industry standards (e.g., ISO 27001, PCI DSS).\n",
            "Would you like to incorporate suggested improvements? (yes/no): yes\n",
            "Architecture:  ## Optimized Initial Architecture Outline for GCP Deployment\n",
            "\n",
            "### High-Level Architecture Diagram\n",
            "\n",
            "[Image of a high-level architecture diagram, indicating the interaction between different GCP services. The diagram should include the following components:\n",
            "- Cloud Load Balancer\n",
            "- Web Server (GCE/GKE)\n",
            "- Cloud SQL\n",
            "- Cloud Storage\n",
            "- Cloud Pub/Sub\n",
            "- Cloud Functions\n",
            "- Stackdriver Logging/Monitoring]\n",
            "\n",
            "### Recommended GCP Services and Tools\n",
            "\n",
            "- **Cloud Load Balancer:** Distributes incoming traffic across multiple backend servers.\n",
            "- **Web Server (GCE/GKE):** Hosts the online store application.\n",
            "- **Cloud SQL:** Manages the relational database for the store.\n",
            "- **Cloud Storage:** Stores images, videos, and other static content.\n",
            "- **Cloud Pub/Sub:** Facilitates communication between different components.\n",
            "- **Cloud Functions:** Handles asynchronous tasks and event-driven operations.\n",
            "- **Stackdriver Logging/Monitoring:** Provides real-time insights into system performance and health.\n",
            "\n",
            "### Data Flow and Storage Strategy\n",
            "\n",
            "- **Data Volume:** A few thousand users visiting the store page.\n",
            "- **Data Velocity:** Moderate, with occasional bursts of traffic.\n",
            "- **Data Variety:** Structured data (user accounts, order details) and unstructured data (images, videos).\n",
            "- **Storage:**\n",
            "    - **Cloud SQL:** Relational database for structured data.\n",
            "    - **Cloud Storage:** Object storage for unstructured data.\n",
            "\n",
            "### Networking and Security Configurations\n",
            "\n",
            "- **VPC and Subnets:** Create a VPC with multiple subnets for different components.\n",
            "- **Firewalls:** Implement firewall rules to restrict access to specific ports and IP addresses.\n",
            "- **IAM Roles:** Assign appropriate IAM roles to users and service accounts.\n",
            "\n",
            "### Monitoring, Logging, and Alerting\n",
            "\n",
            "- **Stackdriver Logging:** Collect and analyze logs from all components.\n",
            "- **Stackdriver Monitoring:** Monitor system metrics and set up alerts for critical events.\n",
            "\n",
            "### Terraform Configurations and Module Recommendations\n",
            "\n",
            "- **Terraform Modules:**\n",
            "    - **VPC and Subnets:** https://registry.terraform.io/modules/terraform-google-modules/vpc/google\n",
            "    - **Cloud SQL:** https://registry.terraform.io/modules/terraform-google-modules/cloudsql/google\n",
            "    - **Cloud Storage:** https://registry.terraform.io/modules/terraform-google-modules/storage/google\n",
            "- **Initial Terraform Configuration:**\n",
            "```\n",
            "resource \"google_compute_network\" \"default\" {\n",
            "  name = \"my-network\"\n",
            "}\n",
            "\n",
            "resource \"google_compute_subnetwork\" \"default\" {\n",
            "  name          = \"my-subnet\"\n",
            "  network       = google_compute_network.default.id\n",
            "  ip_cidr_range = \"10.0.0.0/24\"\n",
            "}\n",
            "\n",
            "resource \"google_cloud_sql_database\" \"default\" {\n",
            "  name         = \"my-database\"\n",
            "  database     = \"my-database\"\n",
            "  instance_type = \"db-f1-micro\"\n",
            "}\n",
            "\n",
            "resource \"google_storage_bucket\" \"default\" {\n",
            "  name          = \"my-bucket\"\n",
            "  location      = \"US-CENTRAL1\"\n",
            "  force_destroy = true\n",
            "}\n",
            "```\n",
            "\n",
            "### Scalability Considerations\n",
            "\n",
            "- **Auto-Scaling:** Scale GCE/GKE instances based on traffic load.\n",
            "- **Load Balancing:** Distribute traffic across multiple instances using Cloud Load Balancer.\n",
            "\n",
            "### Disaster Recovery and Data Backup\n",
            "\n",
            "- **Data Backup:** Regularly back up data in Cloud SQL and Cloud Storage.\n",
            "- **Disaster Recovery:** Implement a disaster recovery plan to restore the system in case of a failure.\n",
            "\n",
            "### Cost Optimization\n",
            "\n",
            "- **Right-size Instances:** Select the appropriate instance types for GCE/GKE based on expected traffic.\n",
            "- **Spot Instances:** Use Spot Instances for GCE/GKE to save on compute costs.\n",
            "- **Cloud Storage Classes:** Optimize storage costs by using the appropriate storage class for different types of data.\n",
            "\n",
            "Incorporated Improvements:\n",
            "**Efficiency Enhancements:**\n",
            "\n",
            "* **Caching:** Implement caching mechanisms (e.g., Redis, Memcached) to reduce database load and improve response times.\n",
            "* **Asynchronous Processing:** Utilize Cloud Functions or Cloud Tasks to handle non-critical tasks asynchronously, freeing up resources for core operations.\n",
            "* **Optimized Database Indexing:** Ensure that Cloud SQL databases are properly indexed to optimize query performance.\n",
            "\n",
            "**Scalability Enhancements:**\n",
            "\n",
            "* **Horizontal Pod Autoscaling (HPA):** Enable HPA for GKE clusters to automatically scale the number of pods based on CPU or memory utilization.\n",
            "* **Managed Instance Groups (MIG):** Use MIGs for GCE instances to automate instance scaling and load balancing.\n",
            "* **Multi-Region Deployment:** Consider deploying the application across multiple GCP regions to improve fault tolerance and reduce latency for geographically dispersed users.\n",
            "\n",
            "**Reliability Enhancements:**\n",
            "\n",
            "* **High Availability Databases:** Utilize Cloud SQL's high availability feature to create replica instances and ensure data redundancy.\n",
            "* **Redundant Storage:** Implement cross-region replication for Cloud Storage buckets to protect against regional outages.\n",
            "* **Disaster Recovery Plan:** Develop a comprehensive disaster recovery plan that includes automated failover and data restoration procedures.\n",
            "\n",
            "**Cost Optimization Enhancements:**\n",
            "\n",
            "* **Preemptible Instances:** Utilize preemptible GCE or GKE instances for non-critical workloads that can tolerate interruptions.\n",
            "* **Committed Use Discounts:** Explore committed use discounts for Cloud SQL and GCE instances to reduce long-term costs.\n",
            "* **Cloud Billing Alerts:** Set up Cloud Billing alerts to monitor and control project spending.\n",
            "\n",
            "**Other Considerations:**\n",
            "\n",
            "* **Serverless Architecture:** Consider migrating certain components (e.g., Cloud Functions, data processing) to serverless services to reduce infrastructure management overhead.\n",
            "* **Performance Monitoring:** Implement performance monitoring tools (e.g., New Relic, Datadog) to continuously monitor system metrics and identify bottlenecks.\n",
            "* **Security Best Practices:** Regularly review and update security configurations to ensure compliance with industry standards (e.g., ISO 27001, PCI DSS).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:308: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:308: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:308: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:308: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Terraform Code:  ```json\n",
            "{\n",
            "  \"corrected_terraform_code\": \"```terraform\n",
            "# VPC and Subnets\n",
            "resource \\\"google_compute_network\\\" \\\"default\\\" {\n",
            "  name = \\\"my-network\\\"\n",
            "}\n",
            "\n",
            "resource \\\"google_compute_subnetwork\\\" \\\"default\\\" {\n",
            "  name          = \\\"my-subnet\\\"\n",
            "  network       = google_compute_network.default.id\n",
            "  ip_cidr_range = \\\"10.0.0.0/24\\\"\n",
            "}\n",
            "\n",
            "# Cloud SQL\n",
            "resource \\\"google_cloud_sql_database\\\" \\\"default\\\" {\n",
            "  name         = \\\"my-database\\\"\n",
            "  database     = \\\"my-database\\\"\n",
            "  instance_type = \\\"db-f1-micro\\\"\n",
            "}\n",
            "\n",
            "# Cloud Storage\n",
            "resource \\\"google_storage_bucket\\\" \\\"default\\\" {\n",
            "  name          = \\\"my-bucket\\\"\n",
            "  location      = \\\"US-CENTRAL1\\\"\n",
            "  force_destroy = true\n",
            "}\n",
            "\n",
            "# Web Server (GCE)\n",
            "resource \\\"google_compute_instance\\\" \\\"web\\\" {\n",
            "  name         = \\\"web-instance\\\"\n",
            "  machine_type = \\\"e2-standard-4\\\"\n",
            "  zone         = \\\"us-central1-a\\\"\n",
            "  network_interface {\n",
            "    network = google_compute_network.default.id\n",
            "    subnetwork = google_compute_subnetwork.default.id\n",
            "  }\n",
            "  disk {\n",
            "    initialize_params {\n",
            "      disk_size_gb = 10\n",
            "      source_image = \\\"projects/debian-cloud/global/images/family/debian-11\\\"\n",
            "    }\n",
            "    auto_delete = true\n",
            "    boot = true\n",
            "  }\n",
            "}\n",
            "\n",
            "# Cloud Load Balancer\n",
            "resource \\\"google_compute_forwarding_rule\\\" \\\"web-forwarding-rule\\\" {\n",
            "  name        = \\\"web-forwarding-rule\\\"\n",
            "  target      = google_compute_instance.web.name\n",
            "  port_range  = \\\"80\\\"\n",
            "  ip_protocol = \\\"tcp\\\"\n",
            "}\n",
            "\n",
            "# Firewall Rules\n",
            "resource \\\"google_compute_firewall\\\" \\\"web-firewall\\\" {\n",
            "  name        = \\\"web-firewall\\\"\n",
            "  network     = google_compute_network.default.id\n",
            "  allow {\n",
            "    protocol = \\\"tcp\\\"\n",
            "    ports    = [\\\"80\\\"]\n",
            "  }\n",
            "  source_ranges = [\\\"0.0.0.0/0\\\"]\n",
            "  target_tags = [\\\"web\\\"]\n",
            "}\n",
            "\n",
            "# IAM Roles\n",
            "resource \\\"google_project_iam_member\\\" \\\"service-account\\\" {\n",
            "  project = \\\"my-project-id\\\"\n",
            "  role    = \\\"roles/compute.instanceAdmin\\\"\n",
            "  member  = \\\"serviceAccount:compute-engine-default@cloudservices.gserviceaccount.com\\\"\n",
            "}\n",
            "```\",\n",
            "  \"linting_summary\": \"## Linting Summary\n",
            "\n",
            "### Corrections Made:\n",
            "\n",
            "- **Argument or Block Definition Missing:** Corrected the syntax error on line 1 by adding a space after the `terraform` command to separate it from the following block definition.\n",
            "\n",
            "### Important Notes:\n",
            "\n",
            "- No additional issues were identified by `tflint` after the corrections were made.\n",
            "- The corrected script now adheres to Terraform's syntax and best practices, ensuring a more robust and compliant configuration.\"\n",
            "}\n",
            "```\n",
            "User confirms this Terraform code? (yes/no): yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents_str = \"Retrieve all files marked as readme files that pertain to this terraform project architecture. Here is the architecture: \"\n",
        "documents_str = architecture + formatted_code\n",
        "retrieved_docs = retriever.get_relevant_documents(documents_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9jCFXWXPIFK",
        "outputId": "a50531f7-1865-4b18-e76d-82b958e81010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:308: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Modifier Chain and Terraform Run Prompt"
      ],
      "metadata": {
        "id": "xtSajkq87tZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "terraform_modification_template = \"\"\"\n",
        "**System Prompt for LLM Handling GCP Terraform Modifications**\n",
        "\n",
        "**Objective:** Modify an existing GCP Terraform project code based on user feedback, while adhering to best practices.\n",
        "\n",
        "**Inputs:**\n",
        "1. **Existing Terraform Code:** A complete Terraform code snippet for a GCP project, provided in a variable `{existing_terraform_code}`.\n",
        "2. **User Feedback:** Specific feedback from the user regarding desired changes or enhancements to the Terraform project, provided in a variable `{user_terraform_feedback}`.\n",
        "\n",
        "**Resources for Reference:**\n",
        "- Database or README files\n",
        "- Main Terraform file (`main.tf`)\n",
        "- Variables file (`variables.tf`)\n",
        "- Outputs file (`outputs.tf`)\n",
        "\n",
        "**Process:**\n",
        "1. **Analyze User Feedback:** Understand the modifications or enhancements requested by the user.\n",
        "2. **Reference Documentation:** Before modifying the code, check the provided documentation and files for existing code snippets that could be reused or adapted.\n",
        "3. **Modify Terraform Code:** Implement the necessary changes to the Terraform code by:\n",
        "   - Adding or updating resources and configurations as per user feedback.\n",
        "   - Ensuring the code follows GCP and Terraform best practices for security, efficiency, and maintainability.\n",
        "   - Avoiding unnecessary changes that do not align with the user's feedback.\n",
        "4. **Quality Assurance:** Double-check the modified code for syntax errors, deprecated functions, and compatibility issues.\n",
        "\n",
        "**Output:**\n",
        "- **Your Terraform Code:** The final modified Terraform code, reflecting the user's feedback and best practices, provided in a variable `{modified_terraform_code}`.\n",
        "\n",
        "**Example (Purely Illustrative):**\n",
        "This example demonstrates how the system might process a simple user request. The actual output will depend entirely on the unique combination of the existing Terraform code and specific user feedback provided.\n",
        "\n",
        "- **Existing Terraform Code:**\n",
        "  ```hcl\n",
        "  resource \"google_compute_instance\" \"default\" {\n",
        "    name         = \"test-instance\"\n",
        "    machine_type = \"e2-medium\"\n",
        "    zone         = \"us-central1-a\"\n",
        "\n",
        "    boot_disk {\n",
        "      initialize_params {\n",
        "        image = \"debian-cloud/debian-9\"\n",
        "      }\n",
        "    }\n",
        "\n",
        "    network_interface {\n",
        "      network = \"default\"\n",
        "      access_config {\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  ```\n",
        "\n",
        "- **User Feedback:**\n",
        "  \"Please change the machine type to 'n1-standard-1' and update the image to the latest Debian version.\"\n",
        "\n",
        "- **Your Terraform Code:**\n",
        "  ```hcl\n",
        "  resource \"google_compute_instance\" \"default\" {\n",
        "    name         = \"test-instance\"\n",
        "    machine_type = \"n1-standard-1\"\n",
        "    zone         = \"us-central1-a\"\n",
        "\n",
        "    boot_disk {\n",
        "      initialize_params {\n",
        "        image = \"debian-cloud/debian-10\"\n",
        "      }\n",
        "    }\n",
        "\n",
        "    network_interface {\n",
        "      network = \"default\"\n",
        "      access_config {\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  ```\n",
        "\"\"\"\n",
        "\n",
        "terraform_modification_prompt = PromptTemplate.from_template(\n",
        "    terraform_modification_template)\n",
        "\n",
        "terraform_modification_chain = ({\n",
        "    \"context\": retriever,\n",
        "    \"existing_terraform_code\": RunnablePassthrough(),\n",
        "    \"user_terraform_feedback\": RunnablePassthrough(),\n",
        "}\n",
        "    | terraform_modification_prompt\n",
        "    | model\n",
        "    | StrOutputParser())\n",
        "\n"
      ],
      "metadata": {
        "id": "YSb6fRIr7jLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Pre-requisites\n",
        "Before you start, ensure you have the following:\n",
        "- A Google Cloud Platform account.\n",
        "- Billing enabled on your GCP account.\n",
        "- Access to create projects and manage billing accounts in GCP.\n",
        "\n",
        "### 2. Install Required Tools\n",
        "You will need to install the following tools:\n",
        "- **Google Cloud SDK**: Download and install the Google Cloud SDK from [here](https://cloud.google.com/sdk/docs/install).\n",
        "- **Terraform**: Download and install Terraform from [here](https://www.terraform.io/downloads.html).\n",
        "\n",
        "### 3. Configure the Google Cloud SDK\n",
        "1. Open a terminal or command prompt.\n",
        "2. Initialize the gcloud tool by running:\n",
        "   ```\n",
        "   gcloud init\n",
        "   ```\n",
        "3. Follow the on-screen instructions to authenticate your Google account and select your default project.\n",
        "\n",
        "### 4. Set Up Terraform Credentials\n",
        "1. Create a service account in your Google Cloud project:\n",
        "   - Go to the IAM & Admin page in the Google Cloud Console.\n",
        "   - Create a new service account with the necessary roles (at least \"Editor\" role or more specific roles depending on your Terraform configuration).\n",
        "2. Create and download a JSON key file for this service account.\n",
        "3. Set the environment variable to authenticate Terraform with Google Cloud:\n",
        "   ```bash\n",
        "   export GOOGLE_APPLICATION_CREDENTIALS=\"[PATH-TO-YOUR-SERVICE-ACCOUNT-KEY-FILE]\"\n",
        "   ```\n",
        "\n",
        "### 5. Prepare the Terraform File\n",
        "- Ensure the Terraform file (e.g., `main.tf`) is configured correctly for your project needs. This file should define your GCP resources.\n",
        "\n",
        "### 6. Initialize Terraform\n",
        "1. Navigate to the directory containing your Terraform file.\n",
        "2. Run the following command to initialize Terraform and download the required providers:\n",
        "   ```bash\n",
        "   terraform init\n",
        "   ```\n",
        "\n",
        "### 7. Plan the Terraform Deployment\n",
        "- Execute the following command to see what resources Terraform will create/modify:\n",
        "  ```bash\n",
        "  terraform plan\n",
        "  ```\n",
        "\n",
        "### 8. Apply the Terraform Configuration\n",
        "- To apply the Terraform configuration and create the resources in GCP, run:\n",
        "  ```bash\n",
        "  terraform apply\n",
        "  ```\n",
        "- Confirm the action by typing `yes` when prompted.\n",
        "\n",
        "### 9. Verify Deployment\n",
        "- Go to the Google Cloud Console and verify that the resources have been created as defined in your Terraform configuration.\n",
        "\n",
        "### 10. Manage Your Infrastructure\n",
        "- Use Terraform to manage the lifecycle of your resources. To update your infrastructure, modify the Terraform files and re-run `terraform apply`.\n",
        "- To destroy the Terraform-managed infrastructure, if needed, use:\n",
        "  ```bash\n",
        "  terraform destroy\n",
        "  ```\n",
        "- Confirm the action by typing `yes` when prompted.\n",
        "\n",
        "By following these steps, you should be able to deploy and manage a GCP project using a Terraform configuration file. Ensure to manage your Terraform state file securely, especially if you are working in a team or on significant projects."
      ],
      "metadata": {
        "id": "v0hYtSdN7TxK"
      }
    }
  ]
}