{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "O_N87YLjB9tG",
        "0N2PlSJCCIbA",
        "VBy8ZA3zCQEn"
      ],
      "authorship_tag": "ABX9TyPCFu4tvpwjkQbC1J01wxZn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkaramb/CloudWeaver/blob/retriever-chain-connection/DB_Connected_Retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "O_N87YLjB9tG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8eFjLBxNLGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019ba441-a3a9-46ff-8a1f-5d014286bc91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m374.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.2/142.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m520.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.5/664.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -U --upgrade --quiet langchain-google-vertexai langchain-google-genai langchain-core langchain-community langchain unstructured lark chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyA7lgFVJCMuPk6V5xm-jxMHh8ndOpo69pY'"
      ],
      "metadata": {
        "id": "q01k3cGoNWyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdztslzkNajN",
        "outputId": "c7295427-23a9-475f-8b40-96e6da7dea35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)"
      ],
      "metadata": {
        "id": "cxQ2nKVtCdmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Access Database contents and metadata"
      ],
      "metadata": {
        "id": "0N2PlSJCCIbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/cw_db_metadata.pkl'"
      ],
      "metadata": {
        "id": "La7hi5UeNbML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the file\n",
        "with open(file_path, 'rb') as file:\n",
        "    documents = pickle.load(file)"
      ],
      "metadata": {
        "id": "qoV2NUzlNwrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents[1356].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDBon6kNR-S8",
        "outputId": "bc46b25d-c3fa-40a2-e201-d7baad2f54aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "/******************************************\n",
            "\tRoutes\n",
            " *****************************************/\n",
            "resource \"google_compute_route\" \"route\" {\n",
            "  provider = google-beta\n",
            "  count    = var.routes_count\n",
            "\n",
            "  project = var.project_id\n",
            "  network = var.network_name\n",
            "\n",
            "  name                   = lookup(var.routes[count.index], \"name\", format(\"%s-%s-%d\", lower(var.network_name), \"route\", count.index))\n",
            "  description            = lookup(var.routes[count.index], \"description\", null)\n",
            "  tags                   = compact(split(\",\", lookup(var.routes[count.index], \"tags\", \"\")))\n",
            "  dest_range             = lookup(var.routes[count.index], \"destination_range\", null)\n",
            "  next_hop_gateway       = lookup(var.routes[count.index], \"next_hop_internet\", \"false\") == \"true\" ? \"default-internet-gateway\" : null\n",
            "  next_hop_ip            = lookup(var.routes[count.index], \"next_hop_ip\", null)\n",
            "  next_hop_instance      = lookup(var.routes[count.index], \"next_hop_instance\", null)\n",
            "  next_hop_instance_zone = lookup(var.routes[count.index], \"next_hop_instance_zone\", null)\n",
            "  next_hop_vpn_tunnel    = lookup(var.routes[count.index], \"next_hop_vpn_tunnel\", null)\n",
            "  next_hop_ilb           = lookup(var.routes[count.index], \"next_hop_ilb\", null)\n",
            "  priority               = lookup(var.routes[count.index], \"priority\", null)\n",
            "\n",
            "  depends_on = [var.module_depends_on]\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retriever"
      ],
      "metadata": {
        "id": "VBy8ZA3zCQEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
        "\n",
        "doc_embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\", task_type=\"retrieval_document\"\n",
        ")\n",
        "\n",
        "# Assuming you've already filtered 'documents' to exclude those with empty 'page_content'\n",
        "# as shown in the previous code snippet:\n",
        "filtered_documents = [doc for doc in documents if doc.page_content and doc.page_content.strip()]\n",
        "\n",
        "# Assuming 'filtered_documents' is your list of Document objects ready for processing\n",
        "# Apply the filter to clean up metadata in your documents\n",
        "cleaned_documents = filter_complex_metadata(filtered_documents)\n",
        "\n",
        "# Now that the documents have been cleaned, you can proceed with creating the vector store\n",
        "vectorstore = Chroma.from_documents(documents=cleaned_documents, embedding=doc_embeddings)\n"
      ],
      "metadata": {
        "id": "rh5kZCMrCWk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "\n",
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"sub_instance\",\n",
        "        description=\"Specifies the exact variant or configuration of the instance that the Terraform code represents. This allows for precise identification of Terraform files based on specific implementations, such as a MySQL version for a Cloud SQL instance, enabling targeted retrieval of code.\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"product\",\n",
        "        description=\"Identifies the broader GCP product category to which an instance belongs. For example, a Compute Engine VM or a Cloud SQL database would fall under 'compute' and 'sql' resources, respectively. This categorization facilitates the organization and search of Terraform files within the context of GCP products.\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"instance\",\n",
        "        description=\"Denotes the specific instance within a GCP product that the Terraform code is designed to provision or manage. This could refer to a particular VM, database, or storage bucket, among others. The instance name aids in pinpointing Terraform files that apply to particular GCP service instances.\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"folder_type\",\n",
        "        description=\"\"\"Modules folder_type:\n",
        "This directory contains Terraform modules, which are pre-packaged configurations for specific use cases. Each module comprises resource and module blocks that encapsulate standard configurations for GCP products or functionalities. These modules are designed for reuse across different parts of the project or in other projects, promoting efficient and scalable infrastructure setups.\n",
        "\n",
        "Examples folder_type:\n",
        "The examples directory showcases how to use the Terraform modules from the modules directory in practical deployments. It includes sample Terraform configurations that reference and instantiate the modules, providing clear, real-world scenarios of module application. This directory is instrumental in demonstrating the modules' utility and easing their adoption by offering ready-to-use examples. \"\"\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"type\",\n",
        "        description=\"\"\"In a Terraform project aimed at deploying and managing resources on the Google Cloud Platform (GCP), three critical files play unique roles in ensuring the configuration's flexibility, clarity, and operational efficiency. These files—`variables.tf`, `main.tf`, and `outputs.tf`—each serve distinct purposes within the Terraform infrastructure as code (IaC) framework.\n",
        "\n",
        "Variables.tf:\n",
        "\n",
        "The `variables.tf` file is fundamental for defining and organizing variables to customize infrastructure deployments across various environments. Each variable is declared with a name, type, description, and optionally, a default value. This structure not only aids in making Terraform configurations modular and reusable but also enhances the maintainability of the code. Variables range from simple placeholders (e.g., project IDs, geographical locations) to complex structures for detailed resource definitions, embodying the principles of IaC by promoting a systematic and customizable approach to cloud resource deployment.\n",
        "\n",
        "Main.tf:\n",
        "\n",
        "At the core of a Terraform project, the `main.tf` file orchestrates the deployment of GCP resources. It integrates:\n",
        "\n",
        "- **Local Variables (`locals`)** to centralize configurations, reducing repetition and enhancing configuration clarity.\n",
        "- **Resource Blocks** to define the GCP resources to be managed or provisioned, including IAM roles and storage buckets.\n",
        "- **Modules** to encapsulate and reuse configurations for efficient resource management.\n",
        "- **Data Sources (`data`)** to incorporate data from GCP or external sources for informed configuration steps.\n",
        "- **IAM and Permissions** to detail the setup for service accounts and specify roles for secure access management.\n",
        "\n",
        "This file exemplifies the declarative nature of IaC, showcasing Terraform's capability to manage a diverse array of resources on GCP through a structured and scalable configuration.\n",
        "\n",
        "Outputs.tf:\n",
        "\n",
        "The `outputs.tf` file is dedicated to defining output variables that relay crucial deployment information to the user. These outputs highlight essential details such as resource identifiers, names, descriptions, and project-specific information, bridging the gap between complex configurations and actionable insights. By making critical deployment information accessible, the outputs.tf file not only enhances the transparency of cloud resources but also supports further automation, integration, and management tasks, emphasizing the importance of information accessibility in IaC practices.\n",
        "\n",
        "README.md:\n",
        "\n",
        "The README.md file serves as the project's documentation hub, containing critical information on how to use the Terraform product, module, or example. It outlines expected inputs, outputs, dependencies, requirements, and use cases, offering a comprehensive guide to navigating and utilizing the Terraform configuration effectively. This file ensures that users have a clear understanding of the project's scope, functionalities, and operational requirements, making it an indispensable resource for successful deployment.\n",
        "Together, these files provide a solid framework for managing infrastructure on GCP with Terraform, leveraging the full potential of IaC to deliver adaptable, scalable, and efficiently managed cloud resources, complemented by thorough documentation for user guidance and project clarity.\n",
        "\n",
        "Together, these files constitute a robust framework for managing infrastructure on GCP with Terraform, leveraging the strengths of IaC to deliver adaptable, scalable, and efficient cloud resource management. \"\"\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "]\n"
      ],
      "metadata": {
        "id": "2hlwJugdRXyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "\n",
        "document_content_description = \"Examples of different components of GCP terraform instances and modules along with readmes describing them.\"\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    model,\n",
        "    vectorstore,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        "    enable_limit=True,\n",
        ")"
      ],
      "metadata": {
        "id": "tO9EZBcYCtQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain"
      ],
      "metadata": {
        "id": "B-IVT2fkDEkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/terraform-linters/tflint/releases/download/v0.34.1/tflint_linux_amd64.zip\n",
        "!unzip tflint_linux_amd64.zip\n",
        "!chmod +x tflint\n",
        "\n",
        "!mv tflint /usr/local/bin/\n",
        "!tflint --version"
      ],
      "metadata": {
        "id": "g97Ka-EJkieY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import tempfile\n",
        "\n",
        "def lint_terraform_code(code):\n",
        "\n",
        "  clean_code = code.replace(\"```\", \"\")\n",
        "\n",
        "  with tempfile.NamedTemporaryFile(delete=False, suffix=\".tf\") as temp_file:\n",
        "    temp_file_name = temp_file.name\n",
        "    temp_file.write(clean_code.encode('utf-8'))\n",
        "\n",
        "  # Write the code to a temporary file\n",
        "  #with open(\"generated.tf\", \"w\") as file:\n",
        "        #file.write(clean_code)\n",
        "\n",
        "  # Run the linter on the file\n",
        "  result = subprocess.run([\"tflint\", temp_file_name], capture_output=True, text=True)\n",
        "\n",
        "  # Ensure the temporary file is removed after linting\n",
        "  os.unlink(temp_file_name)\n",
        "\n",
        "\n",
        "  # Return linting results\n",
        "  return result.stdout + \"\\n\" + result.stderr"
      ],
      "metadata": {
        "id": "l-eEx4MukeTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "# Define the initial prompt template for generating project architecture\n",
        "architecture_prompt_template = \"\"\"Given the detailed project description and user feedback below, generate an optimized initial architecture outline suitable for deployment on Google Cloud Platform (GCP) using Terraform. Aim for a design that balances performance, cost, security, and scalability. Include considerations for key GCP services, data storage options, compute resources, networking setup, and any specific security policies or compliance requirements mentioned. Suggest potential areas for cost optimization without compromising on performance. Address any concerns or modifications suggested in the user feedback explicitly, proposing how the architecture can be adjusted to meet these insights.\n",
        "\n",
        "Project Description:\n",
        "{project_description}\n",
        "\n",
        "User Architecture Feedback:\n",
        "{user_architecture_feedback}\n",
        "\n",
        "To ensure a comprehensive understanding, please include the following in the Initial Architecture Outline:\n",
        "1. A high-level diagram (descriptive) of the proposed architecture, indicating the interaction between different GCP services.\n",
        "2. A list of recommended GCP services and tools, with brief explanations for their selection.\n",
        "3. An overview of the data flow and storage strategy, considering data volume, velocity, and variety.\n",
        "4. Proposed networking and security configurations, including any VPCs, subnets, firewalls, and identity and access management (IAM) roles.\n",
        "5. Strategies for monitoring, logging, and alerting to ensure system health and performance.\n",
        "6. Any initial Terraform configurations or module recommendations that can jump-start the deployment process.\n",
        "7. Suggestions for handling scalability, including any auto-scaling or load balancing configurations.\n",
        "8. Considerations for disaster recovery and data backup strategies to ensure business continuity.\n",
        "\n",
        "Feel free to request additional information or clarification if the project description or user feedback lacks specific details necessary for a well-rounded proposal.\"\"\"\n",
        "\n",
        "\n",
        "# Define the prompt template for generating Terraform code based on confirmed architecture\n",
        "terraform_prompt_template = \"\"\"\n",
        "Given the confirmed architecture outline detailed below, your task is to generate comprehensive Terraform code suitable for deploying the specified project on Google Cloud Platform (GCP). The generated code should accurately reflect the unique infrastructure requirements outlined, emphasizing scalability, security, and cost-efficiency. Utilize the retriever's library of Terraform files — categorized by product and resource, with accompanying README files — as a foundation for your code. This library will serve as a valuable resource for identifying pre-existing configurations that align with the project's needs, thereby streamlining the code development process.\n",
        "\n",
        "When constructing your Terraform configurations, ensure they are tailored to the project's specific requirements by:\n",
        "1. Selecting appropriate GCP services and configuring them to form a secure, scalable, and cost-effective infrastructure.\n",
        "2. Incorporating a Google Compute Engine instance with specifications that support the application's performance needs while optimizing costs.\n",
        "3. Establishing a comprehensive networking setup including VPCs, subnets, and firewall rules to ensure a secure operational environment.\n",
        "4. Defining necessary IAM roles and policies for secure access management across GCP services.\n",
        "5. Integrating storage solutions that accommodate the application's data handling requirements.\n",
        "6. Planning for future growth with scalable solutions like Load Balancing and autoscaling.\n",
        "7. Embedding monitoring, logging, and alerting mechanisms to facilitate efficient infrastructure management.\n",
        "8. Structuring the code for modularity, reusability, and clarity, incorporating documentation where beneficial.\n",
        "\n",
        "Additionally, address any user feedback provided to refine and adjust the Terraform code, focusing on improvements in security, scalability, and efficiency. Your final output should not only align with the confirmed architecture outline but also adhere to best practices in cloud infrastructure design.\n",
        "\n",
        "Confirmed Architecture Outline:\n",
        "{confirmed_architecture}\n",
        "\n",
        "Existing Terraform Code (if any):\n",
        "{existing_terraform_code}\n",
        "\n",
        "User Feedback:\n",
        "{user_terraform_feedback}\n",
        "\n",
        "Your Terraform Code:\n",
        "\"\"\"\n",
        "\n",
        "# Define the prompt template the incorporate the tflint results in the final code generated\n",
        "corrected_terraform_template = \"\"\"\n",
        "\n",
        "Task Description:\n",
        "You will be given the output of `tflint`, a Terraform linter, and a corresponding Terraform script. Your task is to interpret this output, identify issues flagged by the linter, and apply corrections to the Terraform script accordingly. Follow these steps to ensure accuracy and compliance with Terraform standards.\n",
        "\n",
        "Steps to Follow:\n",
        "\n",
        "1. Review `tflint` Output:\n",
        "   - Start by examining the `tflint` output provided. It will detail specific issues including the type of issue, its severity, and the exact location within the Terraform script (file and line number).\n",
        "\n",
        "2. Analyze Each Issue:\n",
        "   - For every issue listed by `tflint`, evaluate the context and the code surrounding the flagged location to understand why it was marked. This includes syntax errors, deprecated elements, and best practice deviations.\n",
        "\n",
        "3. Apply Corrections:\n",
        "   - Direct Corrections: Adjust the script to resolve straightforward issues such as syntax errors or incorrect attribute names according to Terraform’s documentation.\n",
        "   - Best Practices: Update the script to replace hard-coded values with variables, add missing descriptions, or improve resource configurations as recommended by `tflint`.\n",
        "\n",
        "4. Document Changes:\n",
        "   - Add comments within the script next to each change. Briefly describe why the change was made to help with future maintenance and understanding.\n",
        "\n",
        "5. Validation:\n",
        "   - After implementing the changes, check the overall script to ensure that it still aligns with Terraform's syntax and best practices and that no new issues have been introduced.\n",
        "\n",
        "6. Output the Revised Script:\n",
        "   - Provide the corrected Terraform script, highlighting the changes made. Also, include a summary of each correction addressing the specific issues identified by `tflint`.\n",
        "\n",
        "Objective:\n",
        "The goal is to enhance the quality and compliance of the Terraform script based on the `tflint` feedback, making precise corrections without altering the script’s fundamental functionality or intent.\n",
        "\n",
        "Please provide the output in a JSON format with two keys: 'corrected_terraform_code' and 'linting_summary'. The 'corrected_terraform_code' key should contain the formatted Terraform code enclosed in triple backticks for better readability. The 'linting_summary' should provide a markdown-formatted summary of the changes made, including headers and bullet points to outline corrections and important notes. Each key's content should be clear and easy to follow, making it straightforward for developers to understand the corrections and their implications on the code.\n",
        "\n",
        "Existing Terraform Code:\n",
        "{existing_terraform_code}\n",
        "\n",
        "Linter Feedback (`tflint` Output):\n",
        "{tflint_terraform_feedback}\n",
        "\n",
        "Corrected Terraform Code:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Custom prompt templates\n",
        "architecture_prompt = PromptTemplate.from_template(\n",
        "    architecture_prompt_template)\n",
        "terraform_code_prompt = PromptTemplate.from_template(\n",
        "    terraform_prompt_template)\n",
        "\n",
        "# Define the interaction chain for architecture generation and confirmation\n",
        "architecture_chain = ({\n",
        "    \"project_description\": RunnablePassthrough(),\n",
        "    \"user_architecture_feedback\": RunnablePassthrough()\n",
        "}\n",
        "    | architecture_prompt\n",
        "    | model\n",
        "    | StrOutputParser())\n",
        "\n",
        "# Define the interaction chain for Terraform code generation\n",
        "terraform_code_chain = ({\n",
        "    \"context\": retriever,\n",
        "    \"confirmed_architecture\": RunnablePassthrough(),\n",
        "    \"existing_terraform_code\": RunnablePassthrough(),\n",
        "    \"user_terraform_feedback\": RunnablePassthrough(),\n",
        "}\n",
        "    | terraform_code_prompt\n",
        "    | model\n",
        "    | StrOutputParser())\n",
        "\n",
        "# Define the prompt template for suggesting improvements\n",
        "improvement_prompt_template = \"\"\"\n",
        "Given the confirmed architecture outline below, suggest potential improvements that could enhance the project's efficiency, scalability, or reliability.\n",
        "\n",
        "Confirmed Architecture Outline:\n",
        "{confirmed_architecture}\n",
        "\n",
        "Suggested Improvements:\"\"\"\n",
        "\n",
        "improvement_prompt = PromptTemplate.from_template(\n",
        "    improvement_prompt_template)\n",
        "\n",
        "# Define the interaction chain for improvement suggestions\n",
        "improvement_chain = ({\n",
        "    \"context\": retriever,\n",
        "    \"confirmed_architecture\": RunnablePassthrough()\n",
        "}\n",
        "    | improvement_prompt\n",
        "    | model\n",
        "    | StrOutputParser())\n",
        "\n",
        "lint_prompt = PromptTemplate.from_template(\n",
        "    corrected_terraform_template,\n",
        "    additional_instructions=\"Review the linter feedback closely and modify the Terraform script to address each specific issue reported. Ensure to add comments explaining each change for future reference.\"\n",
        "    )\n",
        "\n",
        "# Define the interaction chain for the LLM to communicate with the linter results\n",
        "finalized_code_chain = ({\n",
        "    \"context\": retriever,\n",
        "    \"existing_terraform_code\": RunnablePassthrough(),\n",
        "    \"tflint_terraform_feedback\": RunnablePassthrough()\n",
        "}\n",
        "    | lint_prompt\n",
        "    | model\n",
        "    | StrOutputParser())\n",
        "\n",
        "project_description = input(\"Enter the project description: \")\n",
        "\n",
        "user_architecture_feedback = \"Initial Feedback (None)\"\n",
        "user_terraform_feedback = \"Initial Feedback (None)\"\n",
        "existing_terraform_code = \"\"\n",
        "\n",
        "architecture = None\n",
        "while not architecture:\n",
        "  try:\n",
        "    architecture = architecture_chain.invoke({\n",
        "        \"project_description\": project_description,\n",
        "        \"user_architecture_feedback\": \"user_architecture_feedback\"\n",
        "    })\n",
        "  except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "    break\n",
        "\n",
        "  print(\"Generated Architecture: \", architecture)\n",
        "  user_confirmation = input(\"User confirms this architecture? (yes/no): \")\n",
        "  if user_confirmation.lower() == 'yes':\n",
        "    break\n",
        "  else:\n",
        "    user_architecture_feedback = input(\"Please describe the issues you have with the architecture: \")\n",
        "\n",
        "improvements = improvement_chain.invoke(\n",
        "  {\"confirmed_architecture\": architecture})\n",
        "\n",
        "# Display the suggested improvements to the user\n",
        "print(\"Suggested Improvements: \", improvements)\n",
        "user_confirmation = input(\n",
        "  \"Would you like to incorporate suggested improvements? (yes/no): \")\n",
        "\n",
        "if user_confirmation.lower() == 'yes':\n",
        "    # Update the architecture with the improvements\n",
        "    architecture += \"\\n\\nIncorporated Improvements:\\n\" + improvements\n",
        "\n",
        "# print()\n",
        "# print(architecture)\n",
        "terraform_code_correct = False\n",
        "terraform_code_generated = None\n",
        "while terraform_code_correct == False:\n",
        "  print(\"Architecture: \", architecture)\n",
        "  try:\n",
        "    terraform_code_generated = terraform_code_chain.invoke({\n",
        "        \"confirmed_architecture\": architecture,\n",
        "        \"existing_terraform_code\": existing_terraform_code,\n",
        "        \"user_terraform_feedback\": user_terraform_feedback\n",
        "    })\n",
        "\n",
        "    linter_feedback = lint_terraform_code(terraform_code_generated)\n",
        "\n",
        "    finalized_code = finalized_code_chain.invoke({\n",
        "        \"existing_terraform_code\": terraform_code_generated,\n",
        "        \"tflint_terraform_feedback\": linter_feedback\n",
        "    })\n",
        "\n",
        "    formatted_code = finalized_code.replace(\"\\\\n\", \"\\n\")\n",
        "    print(\"Generated Terraform Code: \", formatted_code)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "    break\n",
        "\n",
        "  #print(\"Generated Terraform Code: \", terraform_code_generated)\n",
        "  #print(\"Generated Terraform Code: \", finalized_code)\n",
        "  user_confirmed_terraform_code = input(\"User confirms this Terraform code? (yes/no): \")\n",
        "  if user_confirmed_terraform_code.lower() == 'yes':\n",
        "    terraform_code_correct = True\n",
        "  else:\n",
        "      existing_terraform_code = terraform_code_generated\n",
        "      user_terraform_feedback = input(\"What is wrong with the code? \")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DgOh58tLDDan"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}